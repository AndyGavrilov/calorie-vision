"""–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∑–∞–¥–∞—á–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞–ª–æ—Ä–∏–π–Ω–æ—Å—Ç–∏ –±–ª—é–¥"""

import os
import pandas as pd
import torch
import timm
from torch.utils.data import Dataset, DataLoader
from torch.nn.utils.rnn import pad_sequence
from PIL import Image
import numpy as np
from transformers import AutoTokenizer
import albumentations as A
import albumentations.pytorch as APT
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')


class CalorieDataset(Dataset):
    """–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞–ª–æ—Ä–∏–π–Ω–æ—Å—Ç–∏ –±–ª—é–¥.
    
    –î–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–∞–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–ª—é–¥, —Ç–∞–∫ –∏ —Å–ø–∏—Å–æ–∫ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤
    –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞–ª–æ—Ä–∏–π–Ω–æ—Å—Ç–∏.
    """
    
    def __init__(
        self, 
        dish_df: pd.DataFrame,
        ingredients_df: pd.DataFrame,
        image_dir: str,
        transforms: Optional[A.Compose] = None,
        mode: str = "train",
        tokenizer_name: Optional[str] = None,
        text_max_length: int = 256
    ):
        """
        Args:
            dish_df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –±–ª—é–¥–∞—Ö
            ingredients_df: DataFrame —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤
            image_dir: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
            transforms: –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            mode: –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã ("train", "val", "test")
        """
        self.dish_df = dish_df
        self.ingredients_df = ingredients_df
        self.image_dir = image_dir
        self.transforms = transforms
        self.mode = mode
        self.text_max_length = text_max_length
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Ä–µ–∂–∏–º—É
        self.filtered_df = dish_df[dish_df['split'] == mode].reset_index(drop=True)
        
        # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ ID -> –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–∞
        self.ingredient_mapping = dict(zip(
            ingredients_df['id'].astype(str).str.zfill(11), 
            ingredients_df['ingr']
        ))
        
        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤ (–±–µ—Ä–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞, –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω)
        tokenizer_model_name = tokenizer_name or 'distilbert-base-uncased'
        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_model_name)
        
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.filtered_df)} –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ä–µ–∂–∏–º–∞ {mode}")
    
    def __len__(self):
        return len(self.filtered_df)
    
    def __getitem__(self, idx: int) -> Dict:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—Ä–∞–∑–µ—Ü –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            idx: –ò–Ω–¥–µ–∫—Å –æ–±—Ä–∞–∑—Ü–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –º–æ–¥–µ–ª–∏:
            - image: —Ç–µ–Ω–∑–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            - text_input_ids: —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã
            - text_attention_mask: –º–∞—Å–∫–∞ –≤–Ω–∏–º–∞–Ω–∏—è
            - calories: —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (–∫–∞–ª–æ—Ä–∏–π–Ω–æ—Å—Ç—å)
            - mass: –º–∞—Å—Å–∞ –±–ª—é–¥–∞
        """
        row = self.filtered_df.iloc[idx]
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image_path = os.path.join(self.image_dir, row['dish_id'], 'rgb.png')
        
        try:
            image = Image.open(image_path).convert('RGB')
            image_array = np.array(image)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path}: {e}")
            # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            image_array = np.zeros((224, 224, 3), dtype=np.uint8)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π
        if self.transforms:
            augmented = self.transforms(image=image_array)
            image = augmented['image']
        else:
            image = torch.from_numpy(image_array).permute(2, 0, 1).float() / 255.0
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤
        ingredients_text = self.convert_ingredients_to_text(row['ingredients'])
        
        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤
        text_encoded = self.tokenizer(
            ingredients_text,
            max_length=self.text_max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        # –ù–æ–≤—ã–π —Ç–∞—Ä–≥–µ—Ç: –∫–∞–ª–æ—Ä–∏–∏ –Ω–∞ 100–≥ (–±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞)
        calories_per_100g = row['total_calories'] / (row['total_mass'] / 100.0)

        # –£—Å—Ç–æ–π—á–∏–≤–æ–µ –ª–æ–≥-–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Å—Å—ã –¥–ª—è –ø—Ä–∏–∑–Ω–∞–∫–∞
        mass_feature = np.log1p(row['total_mass']).astype(np.float32)

        return {
            'image': image,
            'text_input_ids': text_encoded['input_ids'].squeeze(0),
            'text_attention_mask': text_encoded['attention_mask'].squeeze(0),
            # –Ω–æ–≤—ã–π —Ç–∞—Ä–≥–µ—Ç
            'calories_per_100g': torch.tensor(calories_per_100g, dtype=torch.float32),
            # –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞
            'mass': torch.tensor(row['total_mass'], dtype=torch.float32),
            # –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –º–æ–¥–µ–ª–∏
            'mass_feature': torch.tensor(mass_feature, dtype=torch.float32),
            'dish_id': row['dish_id']
        }
    
    def convert_ingredients_to_text(self, ingredients_str: str) -> str:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫—É —Å ID –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤ –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ.
        
        Args:
            ingredients_str: –°—Ç—Ä–æ–∫–∞ –≤–∏–¥–∞ "ingr_0000000508;ingr_0000000122"
            
        Returns:
            –¢–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤
        """
        ingredient_ids = ingredients_str.split(';')
        ingredients = []
        
        for ingr_id in ingredient_ids:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –∏–∑ ID
            clean_id = str(int(ingr_id.replace('ingr_', '')))
            if clean_id in self.ingredient_mapping:
                ingredients.append(self.ingredient_mapping[clean_id])
            else:
                ingredients.append("unknown ingredient")
        
        return ", ".join(ingredients)


def collate_fn(batch: List[Dict]) -> Dict[str, torch.Tensor]:
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –±–∞—Ç—á–∞ –æ–±—Ä–∞–∑—Ü–æ–≤.
    
    Args:
        batch: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ –æ–±—Ä–∞–∑—Ü–æ–≤
        
    Returns:
        –ë–∞—Ç—á —Ç–µ–Ω–∑–æ—Ä–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏
    """
    images = torch.stack([item['image'] for item in batch])
    text_input_ids = torch.stack([item['text_input_ids'] for item in batch])
    text_attention_masks = torch.stack([item['text_attention_mask'] for item in batch])
    calories_per_100g = torch.stack(
        [item['calories_per_100g'] for item in batch])
    masses = torch.stack([item['mass'] for item in batch])
    mass_features = torch.stack([item['mass_feature'] for item in batch])
    dish_ids = [item['dish_id'] for item in batch]
    
    return {
        'images': images,
        'text_input_ids': text_input_ids,
        'text_attention_masks': text_attention_masks,
        'calories_per_100g': calories_per_100g,
        'masses': masses,
        'mass_features': mass_features,
        'dish_ids': dish_ids
    }


def get_transforms(mode: str = "train", image_size: int = 224, config: dict = None) -> A.Compose:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–±–æ—Ä –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ñ–∏–≥–∞ –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π.
    
    Args:
        mode: –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã ("train", "val", "test")
        image_size: –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ resize
        config: –°–ª–æ–≤–∞—Ä—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π
        
    Returns:
        Compose –æ–±—ä–µ–∫—Ç Albumentations
    """
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∏–∑ –º–æ–¥–µ–ª–∏ (–∏–∑ —Ç–µ–æ—Ä–∏–∏)
    try:
        cfg = timm.get_pretrained_cfg('efficientnet_b3')
        optimal_size = max(cfg.input_size[1], cfg.input_size[2])
        print(f"üìê –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –¥–ª—è EfficientNet-B3: {optimal_size}")
    except:
        optimal_size = image_size
    
    # –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –µ—Å–ª–∏ –∫–æ–Ω—Ñ–∏–≥ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω (–æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–æ—Ä–∏–∏)
    if config is None:
        augmentation_config = {
            'image_size': image_size,
            'horizontal_flip_prob': 0.5,
            'color_jitter_prob': 0.9,
            'color_jitter_brightness': 0.4,
            'color_jitter_contrast': 0.4,
            'color_jitter_saturation': 0.4,
            'color_jitter_hue': 0.15,
            'rotation_range': [-15, 15],
            'elastic_transform_prob': 0.3,
            'affine_prob': 0.8,
            'affine_scale': (0.8, 1.2),
            'affine_translate': (-0.1, 0.1),
            'coarse_dropout_prob': 0.5,
            'coarse_dropout_holes_range': (2, 8),
            'transform_seed': 42
        }
        final_image_size = image_size
    else:
        augmentation_config = config.get('augmentation', {})
        final_image_size = augmentation_config.get('image_size', config.get('image_size', image_size))
    
    if mode == "train":
        transforms = A.Compose([
            # Resize: —Å–Ω–∞—á–∞–ª–∞ –¥–µ–ª–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–æ–ª—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞–º–∏, –ø–æ—Ç–æ–º —Å–ª—É—á–∞–π–Ω—ã–π –∫—Ä–æ–ø
            A.SmallestMaxSize(max_size=final_image_size + 32),
            A.RandomCrop(height=final_image_size, width=final_image_size),
            
            # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ
            A.HorizontalFlip(p=augmentation_config.get('horizontal_flip_prob', 0.5)),
            
            # –ú–æ—â–Ω—ã–µ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–∏–∑ —Ç–µ–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
            A.Affine(
                scale=augmentation_config.get('affine_scale', (0.8, 1.2)),
                rotate=augmentation_config.get('rotation_range', [-15, 15]),
                translate_percent=augmentation_config.get('affine_translate', (-0.1, 0.1)),
                shear=(-10, 10),
                fill=0,
                p=augmentation_config.get('affine_prob', 0.8)
            ),
            
            # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ —Ü–≤–µ—Ç–æ–≤—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
            A.ColorJitter(
                brightness=augmentation_config.get('color_jitter_brightness', 0.4),
                contrast=augmentation_config.get('color_jitter_contrast', 0.4),
                saturation=augmentation_config.get('color_jitter_saturation', 0.4),
                hue=augmentation_config.get('color_jitter_hue', 0.15),
                p=augmentation_config.get('color_jitter_prob', 0.9)
            ),
            
            # –£–º–Ω—ã–π CoarseDropout —Å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥—ã—Ä (–∏–∑ —Ç–µ–æ—Ä–∏–∏)
            A.CoarseDropout(
                num_holes_range=augmentation_config.get('coarse_dropout_holes_range', (2, 8)),
                hole_height_range=augmentation_config.get('coarse_dropout_height_range', 
                    (int(0.07 * final_image_size), int(0.15 * final_image_size))),
                hole_width_range=augmentation_config.get('coarse_dropout_width_range', 
                    (int(0.1 * final_image_size), int(0.15 * final_image_size))),
                fill=0,
                p=augmentation_config.get('coarse_dropout_prob', 0.5)
            ),
            
            # –≠–ª–∞—Å—Ç–∏—á–Ω—ã–µ –∏—Å–∫–∞–∂–µ–Ω–∏—è (–º–µ–Ω–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ)
            A.ElasticTransform(
                p=augmentation_config.get('elastic_transform_prob', 0.3)
            ),
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            A.Normalize(
                mean=[0.485, 0.456, 0.406],  # ImageNet mean
                std=[0.229, 0.224, 0.225]   # ImageNet std
            ),
            APT.ToTensorV2()  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä
        ], seed=augmentation_config.get('transform_seed', 42))  # Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    else:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è/—Ç–µ—Å—Ç: —Ç–æ–ª—å–∫–æ resize –∏ normalize, –±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π
        transforms = A.Compose([
            A.SmallestMaxSize(max_size=final_image_size),
            A.CenterCrop(height=final_image_size, width=final_image_size),
            A.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            ),
            APT.ToTensorV2()
        ], seed=augmentation_config.get('transform_seed', 42))  # Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    
    return transforms


def create_data_loaders(
    dish_df: pd.DataFrame,
    ingredients_df: pd.DataFrame,
    image_dir: str,
    batch_size: int = 16,
    num_workers: int = 0,
    config: dict = None
) -> Tuple[DataLoader, DataLoader]:
    """
    –°–æ–∑–¥–∞–µ—Ç DataLoader –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏.
    
    Args:
        dish_df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –±–ª—é–¥–∞—Ö
        ingredients_df: DataFrame —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤
        image_dir: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        num_workers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        config: –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π (–¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ image_size –∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π)
        
    Returns:
        Tuple —Å train –∏ validation DataLoader
    """
    # –ü–æ–ª—É—á–∞–µ–º image_size –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç
    image_size = config.get('image_size', 224) if config else 224
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
    train_dataset = CalorieDataset(
        dish_df=dish_df,
        ingredients_df=ingredients_df,
        image_dir=image_dir,
        transforms=get_transforms(mode="train", image_size=image_size, config=config),
        mode="train",
        tokenizer_name=config.get('text_model') if config else None,
        text_max_length=config.get('text_max_length', 256) if config else 256
    )
    
    val_dataset = CalorieDataset(
        dish_df=dish_df,
        ingredients_df=ingredients_df,
        image_dir=image_dir,
        transforms=get_transforms(mode="val", image_size=image_size, config=config),
        mode="test",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º test —Å–ø–ª–∏—Ç –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        tokenizer_name=config.get('text_model') if config else None,
        text_max_length=config.get('text_max_length', 256) if config else 256
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataLoader
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        collate_fn=collate_fn,
        pin_memory=True if torch.cuda.is_available() else False
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        collate_fn=collate_fn,
        pin_memory=True if torch.cuda.is_available() else False
    )
    
    return train_loader, val_loader
